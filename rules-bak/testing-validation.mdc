---
alwaysApply: false
description: End-to-end viability testing with mathematical data, assertions, and
  print-style debugging for hobby projects
globs:
- '**/test_*.py'
- '**/tests/**/*.py'
- '**/Makefile'
---

# Testing and Validation for Hobby Projects

## End-to-End Viability Tests First
- **VIABILITY TESTS MUST BE END-TO-END** - high level user input â†’ expected output
- **NO PYTEST UNTIL MATURE PHASES** - use basic "make test" command with real workflows
- **RUN AFTER EVERY MAJOR CHANGE** during development
- Example: `echo "Get Arxiv paper 123" | get_arxiv_papers` should produce actual PDFs
- **CHECK REAL OUTPUTS** - use pdftotext, file commands, assertions on actual results
- **SHOULDN'T FAIL ANY ASSERTION ERRORS** - all assertions must pass end-to-end

## Real User Workflows, Not Just Imports
- **TEST THE ACTUAL USE CASE** - what would a real user do with this?
- Import tests are just the bare minimum - prove the workflow works
- Test with real data inputs and verify real outputs exist
- Check file contents, not just file existence
- **CRASH if the end-to-end workflow doesn't work as expected**

## Quick Validation Philosophy
- **PROVE THE CORE IDEA WORKS FIRST** before building test infrastructure
- Use assertions and print statements for immediate feedback
- Test components as you build them, not after
- Focus on catching obvious bugs, not edge cases
- **SURFACE BUGS AS FAST AS POSSIBLE** - don't hide problems

## Print-Style Debugging First
- **LITTER THE CODE WITH PRINT STATEMENTS** while developing
- Print inputs, outputs, intermediate values, function entry/exit
- Use print debugging to trace execution flow and find problems
- **LOG EVERYTHING TEMPORARILY** - better too much info than missing the bug
- Mine stdout to understand what's actually happening vs what you think is happening

## Basic Import and Function Tests (Secondary)
- Test that all modules import without errors (baseline check)
- Test that core functions can be called without crashing
- BUT FOCUS ON END-TO-END WORKFLOWS FIRST
- Use simple Python one-liners in make test: `python -c "from src.module import func; func()"`
- **CRASH IMMEDIATELY if basic imports or function calls fail**

## End-to-End Test Patterns
- Use unix pipes: `echo "input" | command`
- Check outputs exist: `assert_file_exists("output.pdf")`
- Verify content quality: `pdftotext output.pdf - | wc -w` (should be > 100 words)
- Test with realistic inputs that exercise the full system
- **VERIFY ACTUAL FUNCTIONALITY, NOT MOCK RESPONSES**

## Aggressive Logging for Bug Detection
- Log all function calls with parameters and return values
- Log state changes and important variable assignments
- Log conditionals: "Taking branch X because Y=Z"
- Log loop iterations and data structure contents
- **FIND MISTAKES FAST BY LOGGING EVERYTHING POSSIBLE**
- Remove debug logs only after functionality is proven correct

## Iterative Feedback Loops
- After any code modification, run the end-to-end test immediately
- Use quick manual tests to verify core functionality
- Fix obvious issues immediately when you spot them
- Don't build comprehensive test suites for weekend projects
- **CRASH LOUDLY when tests fail - don't continue with broken code**

## Assertions for Quick Debugging
- **TESTS MUST CRASH IMMEDIATELY** on any unexpected behavior
- Use assertions to validate assumptions as you code
- Assert input constraints, output formats, and intermediate states
- Let assertions serve as both documentation and validation
- **NEVER CONTINUE EXECUTION WITH INVALID STATE**

## Performance - Only When Needed
- Don't optimize performance until it becomes a real problem
- Use simple caching only when you notice actual slowness
- Profile performance only if the app feels slow to use
- **Premature optimization is the enemy of getting things working**

## Debug Output Mining
- Use consistent debug output formats for easy parsing
- Include timestamps in debug output when timing matters
- Use distinctive prefixes for different types of debug output
- Example: "DEBUG_INPUT: user_id=123", "DEBUG_OUTPUT: result=success"
- Grep through debug output to find patterns and problems

## Validation Priorities for Hobby Projects
1. **Does the end-to-end workflow work with real inputs?**
2. **Do the modules import without errors?** (baseline)
3. **Do the core functions run without crashing?**
4. **Can I trace the execution flow through debug output?**
5. **Do assertions catch problems immediately?**
6. **Can I use this for my actual use case?**
7. **Is it fast enough for my needs?**

**Only move to pytest/comprehensive testing when the project proves valuable and mature.**

Stop at basic viability unless the project grows beyond hobby scope.
---
