#!/bin/bash
# Download advanced Ollama models for better performance
# Requires more RAM/VRAM - see .ai/ollama-setup.md for requirements

echo "ğŸš€ Downloading advanced Ollama models..."
echo "âš ï¸  These models require significant RAM/VRAM:"
echo "   - 13B models: 16GB RAM minimum"
echo "   - 33B models: 24GB RAM minimum" 
echo "   - 70B models: 48GB RAM minimum"
echo ""

read -p "Continue? (y/N): " -n 1 -r
echo
if [[ ! $REPLY =~ ^[Yy]$ ]]; then
    echo "Cancelled."
    exit 1
fi

# Check available RAM
total_ram=$(free -g | awk '/^Mem:/{print $2}')
echo "ğŸ’¾ Detected ${total_ram}GB total RAM"

if [ "$total_ram" -lt 16 ]; then
    echo "âš ï¸  Warning: Less than 16GB RAM detected. Large models may not run well."
fi

# Download based on available RAM
if [ "$total_ram" -ge 48 ]; then
    echo "ğŸ“¦ Downloading 70B models (excellent performance)..."
    ollama pull llama3.1:70b-instruct-q4_K_M
    echo "âœ… Llama 3.1 70B downloaded"
fi

if [ "$total_ram" -ge 32 ]; then
    echo "ğŸ“¦ Downloading Mixtral 8x7B (excellent multilingual)..."
    ollama pull mixtral:8x7b-instruct-q4_K_M
    echo "âœ… Mixtral 8x7B downloaded"
fi

if [ "$total_ram" -ge 24 ]; then
    echo "ğŸ“¦ Downloading 33B code model..."
    ollama pull deepseek-coder:33b-instruct-q4_K_M
    echo "âœ… DeepSeek Coder 33B downloaded"
fi

if [ "$total_ram" -ge 16 ]; then
    echo "ğŸ“¦ Downloading 13B reasoning model..."
    ollama pull nous-hermes2:13b-q4_K_M
    echo "âœ… Nous Hermes 13B downloaded"
else
    echo "â„¹ï¸  Skipping large models due to RAM limitations"
    echo "   Consider upgrading to 16GB+ RAM for better performance"
fi

echo ""
echo "âœ… Advanced models download complete!"
echo ""
echo "ğŸ“Š Updated model hierarchy:"
if [ "$total_ram" -ge 48 ]; then
    echo "ğŸ¥‡ Reasoning: llama3.1:70b-instruct-q4_K_M (best)"
fi
if [ "$total_ram" -ge 32 ]; then
    echo "ğŸ¥‡ Multilingual: mixtral:8x7b-instruct-q4_K_M"
fi
if [ "$total_ram" -ge 24 ]; then
    echo "ğŸ¥‡ Code: deepseek-coder:33b-instruct-q4_K_M (best)"
fi
if [ "$total_ram" -ge 16 ]; then
    echo "ğŸ¥‡ General: nous-hermes2:13b-q4_K_M (better)"
fi
echo ""
echo "ğŸ’¡ Update your model routing config to use these advanced models"
echo "ğŸ“š See .ai/ollama-setup.md for integration instructions"