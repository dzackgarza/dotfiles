#!/usr/bin/env python3
# Script for converting natural language to shell commands using Groq

import os
import re
import sys
import json
import subprocess
from pathlib import Path
from enum import Enum
from typing import Optional, List, Dict, Any, Type, TypeVar, Union
from pydantic import BaseModel, Field, field_validator, model_validator, ValidationError
import instructor
from groq import Groq
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# --- Constants ---
MAX_RETRIES = 3

# Model Selection and Rate Limits (as of July 2025):
# -------------------------------------------------
# llama-3.1-8b-instant:
#   - Tokens per Minute (TPM): 10,000+
#   - Requests per Minute (RPM): 100+
#   - Best for: High throughput, low latency, and high rate limits
#   - Use case: General purpose, high-volume applications
#
# Other available models (for reference):
# llama-3.3-70b-versatile:
#   - TPM: 5,000
#   - RPM: 50
#   - Best for: More complex tasks requiring higher reasoning capability
#
# meta-llama/llama-4-scout-17b-16e-instruct:
#   - TPM: 7,500
#   - RPM: 75
#   - Best for: Instruction following and tool use
#
# Note: Rate limits are subject to change. Check https://console.groq.com/dashboard/limits for current limits.
MODEL_NAME = "llama-3.1-8b-instant"  # Selected for highest rate limits and low latency

# --- Enums ---
class CommandSafety(str, Enum):
    SAFE = "safe"  # Read-only operations
    CAUTION = "caution"  # Modifies files but safe with confirmation
    DESTRUCTIVE = "destructive"  # Potentially harmful operations

# --- Models ---
class CommandResponse(BaseModel):
    command: str = Field(..., description="The exact bash/zsh command to execute")
    safety: CommandSafety = Field(..., description="Safety level of the command")
    description: str = Field(..., description="Brief description of what the command does")
    confirm_message: Optional[str] = Field(
        None,
        description="Additional warning message to show for dangerous commands"
    )
    
    # Field-level validation
    @field_validator('command')
    @classmethod
    def validate_command_syntax(cls, v: str) -> str:
        v = v.strip()
        if not v:
            raise ValueError("Command cannot be empty")
        return v

    # Security validation
    @field_validator('command')
    @classmethod
    def validate_command_safety(cls, v: str) -> str:
        dangerous_patterns = [
            (r'\b(rm|dd|mkfs|shred|mkfifo)\b', "Potentially dangerous command"),
            (r'`.*`', "Command substitution not allowed"),
            (r'\$\(.*\)', "Command substitution not allowed"),
            (r'\|.*(sh|bash|zsh)\s*$', "Piping to shell not allowed"),
            (r'^(sudo|pkexec)\b', "Privilege escalation not allowed"),
            (r'^.{500,}$', "Command too long"),
            (r'wget\s+[^ ]*-[^ ]*O\s+', "Suspicious wget output redirection"),
            (r'curl\s+[^ ]*-[^ ]*o\s+', "Suspicious curl output redirection"),
        ]
        
        for pattern, msg in dangerous_patterns:
            if re.search(pattern, v, re.IGNORECASE):
                raise ValueError(f"Security check failed: {msg} - {v}")
        return v

    # Context-aware validation
    @model_validator(mode='after')
    def validate_in_context(self, info) -> 'CommandResponse':
        context = info.context or {}
        
        # Prevent operations outside git repo
        if 'git_root' in context and context['git_root']:
            if any(op in self.command for op in ['>', '>>', '| tee']):
                if not any(f'>{context["git_root"]}' in part 
                          for part in self.command.split()):
                    raise ValueError(
                        "File operations must be within git repository"
                    )
        
        # Ensure destructive commands have confirmation
        if self.safety == CommandSafety.DESTRUCTIVE and not self.confirm_message:
            self.confirm_message = "This is a destructive operation that cannot be undone."
            
        return self

def get_api_key() -> str:
    """Get API key from environment or config file."""
    if "GROQ_API_KEY" in os.environ:
        return os.environ["GROQ_API_KEY"]
    
    config_path = Path.home() / ".config" / "groq" / "api_key"
    if config_path.exists():
        return config_path.read_text().strip()
    
    print("Error: GROQ_API_KEY not set and ~/.config/groq/api_key not found")
    print("Get an API key from: https://console.groq.com/keys")
    sys.exit(1)

def get_git_root() -> Optional[str]:
    """Get the git root directory if in a git repo."""
    try:
        return subprocess.run(
            ["git", "rev-parse", "--show-toplevel"],
            capture_output=True,
            text=True,
            check=True
        ).stdout.strip()
    except subprocess.CalledProcessError:
        return None

def get_system_prompt() -> str:
    """Generate the system prompt with current context."""
    current_dir = os.getcwd()
    git_root = get_git_root() or current_dir
    git_branch = None
    
    if git_root:
        try:
            git_branch = subprocess.run(
                ["git", "branch", "--show-current"],
                cwd=git_root,
                capture_output=True,
                text=True
            ).stdout.strip()
        except subprocess.CalledProcessError:
            pass
    
    prompt = f"""You are a zsh terminal expert. Convert natural language requests into executable commands.

Current directory: {current_dir}
Git root: {git_root or "N/A"}
Git branch: {git_branch or "N/A"}

Rules:
1. Only return the exact command, no explanations
2. Use relative paths when possible
3. Add safety checks when appropriate
4. Prefer built-in commands over installing new tools
5. If the request is unclear or potentially harmful, set safety to "destructive"
6. For file operations, use safe patterns (e.g., --interactive, --no-clobber)
7. Never use sudo or other escalation commands

For potentially destructive operations, provide a clear confirm_message explaining the risks."""
    return prompt

def get_llm_response(
    query: str,
    response_model: Type[BaseModel],
    max_retries: int = MAX_RETRIES,
    **kwargs
) -> BaseModel:
    """
    Get a validated response from the LLM with automatic retries.
    
    Args:
        query: The user's natural language query
        response_model: Pydantic model for validation
        max_retries: Maximum number of retry attempts
        **kwargs: Additional context for validation
    """
    client = instructor.from_groq(
        Groq(api_key=get_api_key()),
        mode=instructor.Mode.JSON
    )
    
    messages = [
        {"role": "system", "content": get_system_prompt()},
        {"role": "user", "content": query}
    ]
    
    retry_count = 0
    last_error = None
    
    while retry_count <= max_retries:
        try:
            response = client.chat.completions.create(
                model=MODEL_NAME,
                response_model=response_model,
                messages=messages,
                temperature=0.3,
                context=kwargs.get('context', {})
            )
            return response
            
        except (ValidationError, Exception) as e:
            last_error = str(e)
            retry_count += 1
            
            if retry_count <= max_retries:
                # Add error to messages for context
                error_msg = f"Previous error (attempt {retry_count}/{max_retries}): {last_error}"
                messages.append({
                    "role": "system",
                    "content": error_msg
                })
            else:
                raise ValueError(f"Failed after {max_retries} attempts. Last error: {last_error}")
    
    raise ValueError(f"Failed to get valid response: {last_error}")

def confirm_execution(response: CommandResponse) -> bool:
    """Get user confirmation before executing a command."""
    print(f"\nCommand: {response.command}")
    print(f"Description: {response.description}")
    print(f"Safety: {response.safety.value.upper()}")
    
    if response.confirm_message:
        print(f"\n⚠️  WARNING: {response.confirm_message}")
    
    if response.safety == CommandSafety.DESTRUCTIVE:
        confirm = input("\nThis is a DESTRUCTIVE operation. Type 'CONFIRM' to proceed: ")
        return confirm.strip().upper() == "CONFIRM"
    elif response.safety == CommandSafety.CAUTION:
        confirm = input("\nThis operation will modify files. Continue? [y/N] ")
        return confirm.strip().lower() == "y"
    else:  # SAFE
        confirm = input("\nExecute? [y/N] ")
        return confirm.strip().lower() == "y"

def execute_command(command: str) -> int:
    """Execute a shell command with proper error handling."""
    try:
        result = subprocess.run(
            command,
            shell=True,
            executable="/bin/zsh",
            check=True,
            text=True
        )
        return result.returncode
    except subprocess.CalledProcessError as e:
        print(f"\n❌ Command failed with exit code {e.returncode}:")
        print(e.stderr or e.stdout or "No output")
        return e.returncode
    except Exception as e:
        print(f"\n❌ Error executing command: {str(e)}")
        return 1

def main():
    if len(sys.argv) < 2:
        print("Usage: askterm 'your natural language query'")
        sys.exit(1)
    
    query = " ".join(sys.argv[1:])
    
    try:
        # Get context for validation
        context = {
            'git_root': get_git_root(),
            'current_dir': os.getcwd()
        }
        
        # Get and validate command
        response = get_llm_response(
            query,
            CommandResponse,
            context=context
        )
        
        # Just print the command to be executed
        print(response.command)
        return 0
            
    except Exception as e:
        print(f"\n❌ Error: {str(e)}", file=sys.stderr)
        return 1

if __name__ == "__main__":
    sys.exit(main())
